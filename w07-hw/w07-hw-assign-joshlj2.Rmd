---
title: "Week 7 - Homework"
author: "STAT 420, Summer 2019, Janda - joshlj2"
date: ''
output:
  html_document: 
    toc: yes
  pdf_document: default
urlcolor: cyan
---


```{r setup}
options(scipen = 1, digits = 4, width = 80, fig.alin = "center")
library(tinytex)
```

## Exercise 1 (EPA Emissions Data)

For this exercise, we will use the data stored in [`epa2015.csv`](epa2015.csv). It contains detailed descriptions of 4,411 vehicles manufactured in 2015 that were used for fuel economy testing [as performed by the Environment Protection Agency]( https://www3.epa.gov/otaq/tcldata.htm). The variables in the dataset are:  

- `Make` - Manufacturer
- `Model` - Model of vehicle
- `ID` - Manufacturer defined vehicle identification number within EPA's computer system (not a VIN number)
- `disp` - Cubic inch displacement of test vehicle
- `type` - Car, truck, or both (for vehicles that meet specifications of both car and truck, like smaller SUVs or crossovers)
- `horse` - Rated horsepower, in foot-pounds per second
- `cyl` - Number of cylinders
- `lockup` - Vehicle has transmission lockup; N or Y
- `drive` - Drivetrain system code
    - A = All-wheel drive
    - F = Front-wheel drive
    - P = Part-time 4-wheel drive
    - R = Rear-wheel drive
    - 4 = 4-wheel drive
- `weight` - Test weight, in pounds
- `axleratio` - Axle ratio
- `nvratio` - n/v ratio (engine speed versus vehicle speed at 50 mph)
- `THC` - Total hydrocarbons, in grams per mile (g/mi)
- `CO` - Carbon monoxide (a regulated pollutant), in g/mi
- `CO2` - Carbon dioxide (the primary byproduct of all fossil fuel combustion), in g/mi
- `mpg` - Fuel economy, in miles per gallon

We will attempt to model `CO2` using both `horse` and `type`. In practice, we would use many more predictors, but limiting ourselves to these two, one numeric and one factor, will allow us to create a number of plots.

Load the data, and check its structure using `str()`. Verify that `type` is a factor; if not, coerce it to be a factor.

**(a)** Do the following:

- Make a scatterplot of `CO2` versus `horse`. Use a different color point for each vehicle `type`.
- Fit a simple linear regression model with `CO2` as the response and only `horse` as the predictor.
- Add the fitted regression line to the scatterplot. Comment on how well this line models the data.
- Give an estimate for the average change in `CO2` for a one foot-pound per second increase in `horse` for a vehicle of type `car`. 
- Give a 90% prediction interval using this model for the `CO2` of a Subaru Impreza Wagon, which is a vehicle with 148 horsepower and is considered type `Both`. (Interestingly, the dataset gives the wrong drivetrain for most Subarus in this dataset, as they are almost all listed as `F`, when they are in fact all-wheel drive.)
```{r}
library(readr)
library(ggplot2)
epa = read_csv("epa2015.csv")

ggplot(epa, aes(x = horse, y = CO2, color = type)) +
  geom_point() +
  xlab("Horsepower of Vehicle") +
  ylab("CO2 Pollution (g/mi)") +
  ggtitle("CO2 Pollution vs Horsepower, Sorted by Vehicle Type") +
  theme(plot.title = element_text(hjust = .5)) +
  labs(color = "Type of Vehicle") +
  geom_smooth(method = 'lm', formula = y ~ x, color = 'grey')

simple_modq1a = lm(CO2 ~ horse, data = epa)
slopehorse = simple_modq1a$coefficients[2]

q1a_pred = predict.lm(simple_modq1a,
                       data.frame(horse = 148),
                       level = .90,
                       interval = "prediction"
                       ) 
q1a_lower = q1a_pred[2]
q1a_upper = q1a_pred[3]
  



```
</br>
The graph above shows a plot of CO2 Pollution (g/mi) vs Horsepower, with the data sorted by vehicle type. The regression line in the plot seems to the fit the data just okay. There is definitely a linear relationship between horsepower and CO2 pollution, but the type of vehicle needs to be taken into effect I believe which this regression line does not.
</br>
</br>
An estimate for the average change in "CO2" when horsepower is increased by one for vehicle of type "car" is `r slopehorse`. The estimate for the average change in "CO2" when horsepower is increased by one for any vehicle is the same due to the only difference between the vehicle types being the intercept.
</br>
</br>
The 90% prediction interval of a vehicle of type "both"  with 148 horsepower is: [`r q1a_lower`, `r q1a_upper`]. This prediction interval represents that we are 90% confident that a specific Subaru Impreza Wagon will output CO2 pollution in this range. Also, note that our simple model does not include vehicle type as a predictor so the vehicle type does not affect our results.
</br>

**(b)** Do the following:

- Make a scatterplot of `CO2` versus `horse`. Use a different color point for each vehicle `type`.
- Fit an additive multiple regression model with `CO2` as the response and `horse` and `type` as the predictors.
- Add the fitted regression "lines" to the scatterplot with the same colors as their respective points (one line for each vehicle type). Comment on how well this line models the data. 
- Give an estimate for the average change in `CO2` for a one foot-pound per second increase in `horse` for a vehicle of type `car`. 
- Give a 90% prediction interval using this model for the `CO2` of a Subaru Impreza Wagon, which is a vehicle with 148 horsepower and is considered type `Both`. 

```{r}


q1mod_b = lm(CO2 ~ horse + type, data = epa)
slopehorse = q1mod_b$coefficients[2]
int_both = q1mod_b$coefficients[1]
int_car = q1mod_b$coefficients[1] + q1mod_b$coefficients[3]
int_truck = q1mod_b$coefficients[1] + q1mod_b$coefficients[4]

ggplot(epa, aes(x = horse, y = CO2, color = type)) +
  geom_point() +
  xlab("Horsepower of Vehicle") +
  ylab("CO2 Pollution (g/mi)") +
  ggtitle("CO2 Pollution vs Horsepower, Sorted by Vehicle Type") +
  theme(plot.title = element_text(hjust = .5)) +
  labs(color = "Type of Vehicle") +
  geom_abline(intercept = int_both, slope = slopehorse, color = "red") +
  geom_abline(intercept = int_car, slope = slopehorse, color = "forestgreen") +
  geom_abline(intercept = int_truck, slope = slopehorse, color = 'blue') +
  scale_color_manual(
                      values = c("red", "forestgreen", "blue"),
                      labels = c("Both", "Car", "Truck")
                    )

q1b_pred = predict.lm(q1mod_b,
                       data.frame(horse = 148, type = "Both"),
                       level = .90,
                       interval = "prediction"
                       )

q1b_lower = q1b_pred[2]
q1b_upper = q1b_pred[3]
```
</br>
The graph above shows a plot of CO2 Pollution (g/mi) vs Horsepower, with the data sorted by vehicle type. The regression lines in the plot seem to fit the data still just okay, but are better than the simple model line in part a. There is definitely a linear relationship between horsepower and CO2 pollution, and different intercepts for each type of vehicle helps model this relationship better.
</br>
</br>
An estimate for the average change in "CO2" when horsepower is increased by one for vehicle of type "car" is `r slopehorse`. The estimate for the average change in "CO2" when horsepower is increased by one for any vehicle is the same due to the only difference between the vehicle types being the intercept.
</br>
</br>
The 90% prediction interval of a vehicle of type "both"  with 148 horsepower is: [`r q1b_lower`, `r q1b_upper`]. This prediction interval represents that we are 90% confident that a specific Subaru Impreza Wagon will output CO2 pollution in this range.
</br>

**(c)** Do the following:

- Make a scatterplot of `CO2` versus `horse`. Use a different color point for each vehicle `type`. 
- Fit an interaction multiple regression model with `CO2` as the response and `horse` and `type` as the predictors.
- Add the fitted regression "lines" to the scatterplot with the same colors as their respective points (one line for each vehicle type). Comment on how well this line models the data. 
- Give an estimate for the average change in `CO2` for a one foot-pound per second increase in `horse` for a vehicle of type `car`. 
- Give a 90% prediction interval using this model for the `CO2` of a Subaru Impreza Wagon, which is a vehicle with 148 horsepower and is considered type `Both`. 
```{r}
q1mod_c = lm(CO2 ~ horse*type, data = epa)
slopeboth = q1mod_c$coefficients[2]
slopecar = q1mod_c$coefficients[2] + q1mod_c$coefficients[5]
slopetruck = q1mod_c$coefficients[2] + q1mod_c$coefficients[6]
int_both = q1mod_c$coefficients[1]
int_car = q1mod_c$coefficients[1] + q1mod_c$coefficients[3]
int_truck = q1mod_c$coefficients[1] + q1mod_c$coefficients[4]

ggplot(epa, aes(x = horse, y = CO2, color = type)) +
  geom_point() +
  xlab("Horsepower of Vehicle") +
  ylab("CO2 Pollution (g/mi)") +
  ggtitle("CO2 Pollution vs Horsepower, Sorted by Vehicle Type") +
  theme(plot.title = element_text(hjust = .5)) +
  labs(color = "Type of Vehicle") +
  geom_abline(intercept = int_both, slope = slopeboth, color = "red") +
  geom_abline(intercept = int_car, slope = slopecar, color = "forestgreen") +
  geom_abline(intercept = int_truck, slope = slopetruck, color = 'blue') +
  scale_color_manual(
                      values = c("red", "forestgreen", "blue"),
                      labels = c("Both", "Car", "Truck")
                    )

q1c_pred = predict.lm(q1mod_c,
                       data.frame(horse = 148, type = "Both"),
                       level = .90,
                       interval = "prediction"
                       )

q1c_lower = q1c_pred[2]
q1c_upper = q1c_pred[3]
```
</br>
The graph above shows a plot of CO2 Pollution (g/mi) vs Horsepower, with the data sorted by vehicle type. The regression lines in the plot seem to fit the data much better than the other models. There is definitely a linear relationship between horsepower and CO2 pollution, and different intercepts for each type of vehicle helps model this relationship better. The different slopes for each vehicle type help as well to show the difference in interactions between horsepower and vehicle type and that affect on CO2 pollution.
</br>
</br>
An estimate for the average change in "CO2" when horsepower is increased by one for vehicle of type "car" is `r slopecar`. We must take into consideration the interaction between the horsepower coefficient and type variable. This will affect the slopes for each vehicle type, and give each type a different slope. We can see this in the plot above.
</br>
</br>
The 90% prediction interval of a vehicle of type "both"  with 148 horsepower is: [`r q1c_lower`, `r q1c_upper`]. This prediction interval represents that we are 90% confident that a specific Subaru Impreza Wagon will output CO2 pollution in this range.
</br>

**(d)** Based on the previous plots, you probably already have an opinion on the best model. Now use an ANOVA $F$-test to compare the additive and interaction models. Based on this test and a significance level of $\alpha = 0.10$, which model is preferred?
```{r}
ftest = anova(q1mod_b, q1mod_c)
fstat = ftest$F[2]
pval = pf(fstat, ftest$Df, ftest$Res.Df, lower.tail=FALSE)[2]


```
</br>
Based on the anova F-Test above, the apparent best model is the interaction model. The F-Test has a p-value of `r pval`, so we can reject the null hypothesis that the interaction variable coefficients are equal to zero at $\alpha = .10$. I prefer the interaction model.
</br>

***

## Exercise 2 (Hospital SUPPORT Data, White Blood Cells)

For this exercise, we will use the data stored in [`hospital.csv`](hospital.csv). It contains a random sample of 580 seriously ill hospitalized patients from a famous study called "SUPPORT" (Study to Understand Prognoses Preferences Outcomes and Risks of Treatment). As the name suggests, the purpose of the study was to determine what factors affected or predicted outcomes, such as how long a patient remained in the hospital. The variables in the dataset are:  
 
- `Days` - Days to death or hospital discharge
- `Age` - Age on day of hospital admission
- `Sex` - Female or male
- `Comorbidity` - Patient diagnosed with more than one chronic disease
- `EdYears` - Years of education
- `Education` - Education level; high or low
- `Income` - Income level; high or low
- `Charges` - Hospital charges, in dollars
- `Care` - Level of care required; high or low
- `Race` - Non-white or white
- `Pressure` - Blood pressure, in mmHg
- `Blood` - White blood cell count, in gm/dL
- `Rate` - Heart rate, in bpm

For this exercise, we will use `Age`, `Education`, `Income`, and `Sex` in an attempt to model `Blood`. Essentially, we are attempting to model white blood cell count using only demographic information.

**(a)** Load the data, and check its structure using `str()`. Verify that `Education`, `Income`, and `Sex` are factors; if not, coerce them to be factors. What are the levels of `Education`, `Income`, and `Sex`?
```{r}
hospital = read_csv("hospital.csv")
hospital$Education = as.factor(hospital$Education)
hospital$Income = as.factor(hospital$Income)
hospital$Sex = as.factor(hospital$Sex)
str(hospital)
```
</br>
The levels of Education are: Low and High. In this dataset, the subjects either have low or high education.
</br>
</br>
The levels of Income are: Low and High. In this dataset, the subjects either have low or high income.
</br>
</br>
The levels of Sex are: Female and Male. In this dataset, female is equal to 1 and male is equal to 2.
</br>

**(b)** Fit an additive multiple regression model with `Blood` as the response using `Age`, `Education`, `Income`, and `Sex` as predictors. What does `R` choose as the reference level for `Education`, `Income`, and `Sex`?
```{r}
q2_addmod = lm(Blood ~ Age + Education + Income + Sex, data = hospital)
dummy.coef(q2_addmod)
```
</br>
For Education, R chooses high education as the refence level. For Income, R chooses high income as the reference level. For Sex, R chooses female as the reference level. We can see this as the dummy coefficients on high Education, high Income, and female Sex are equal to zero.
</br>

**(c)** Fit a multiple regression model with `Blood` as the response. Use the main effects of `Age`, `Education`, `Income`, and `Sex`, as well as the interaction of `Sex` with `Age` and the interaction of `Sex` and `Income`. Use a statistical test to compare this model to the additive model using a significance level of $\alpha = 0.10$. Which do you prefer?
```{r}
q2_intmod = lm(Blood ~ Age + Education + Income + Sex + Sex:Age + Sex:Income, data = hospital)
q2_fteststat = anova(q2_addmod, q2_intmod)$F[2]
q2_pval = pf(q2_fteststat, 2, 573, lower.tail = FALSE)

```
</br>
When comparing these two models, we have a null hypothesis that the coefficients on the interactions between Sex and Income and Sex and Age are equal to zero. When performing the test, we get a p-value of: `r q2_pval`. So comparing to a significance level of $\alpha = .10$, we fail to reject the null hypothesis and conclude that the additive model is better than the interaction model.
</br>

**(d)** Fit a model similar to that in **(c)**, but additionally add the interaction between `Income` and `Age` as well as a three-way interaction between `Age`, `Income`, and `Sex`. Use a statistical test to compare this model to the preferred model from **(c)** using a significance level of $\alpha = 0.10$. Which do you prefer?
```{r}
q2_intmod2 = lm(Blood ~ Age + Education + Income + Sex + Sex:Age + Sex:Income + Income:Age + Age:Income:Sex, data = hospital)
q2_fteststat2 = anova(q2_addmod, q2_intmod2)$F[2]
q2_pval2 = pf(q2_fteststat, 4, 571, lower.tail = FALSE)

```
</br>
In the last statistical test, we chose the additive model over the first interactive model.
</br>
</br>
When comparing these two models (additive and new interaction model built above), we have a null hypothesis that the coefficients on the interactions between Sex and Income, Sex and Age, Income and Age, and the three way interaction between Age, Income and Sex are equal to zero. When performing the test, we get a p-value of: `r q2_pval2`. So comparing to a significance level of $\alpha = .10$, we reject the null hypothesis and conclude that this interaction model is better than the additive model.
</br>

**(e)** Using the model in **(d)**, give an estimate of the change in average `Blood` for a one-unit increase in `Age` for a highly educated, low income, male patient.
```{r}
q2_avgchange = q2_intmod2$coefficients[2] + 
  q2_intmod2$coefficients[6] +
  q2_intmod2$coefficients[8] +
  q2_intmod2$coefficients[9]
  
```
</br>
An estimate for the change in average Blood for a one-unit increase in Age for a highly educated, low income, and male patient is: `r q2_avgchange`.
</br>

***

## Exercise 3 (Hospital SUPPORT Data, Stay Duration)

For this exercise, we will again use the data stored in [`hospital.csv`](hospital.csv). It contains a random sample of 580 seriously ill hospitalized patients from a famous study called "SUPPORT" (Study to Understand Prognoses Preferences Outcomes and Risks of Treatment). As the name suggests, the purpose of the study was to determine what factors affected or predicted outcomes, such as how long a patient remained in the hospital. The variables in the dataset are:  
 
- `Days` - Days to death or hospital discharge
- `Age` - Age on day of hospital admission
- `Sex` - Female or male
- `Comorbidity` - Patient diagnosed with more than one chronic disease
- `EdYears` - Years of education
- `Education` - Education level; high or low
- `Income` - Income level; high or low
- `Charges` - Hospital charges, in dollars
- `Care` - Level of care required; high or low
- `Race` - Non-white or white
- `Pressure` - Blood pressure, in mmHg
- `Blood` - White blood cell count, in gm/dL
- `Rate` - Heart rate, in bpm

For this exercise, we will use `Blood`, `Pressure`, and `Rate` in an attempt to model `Days`. Essentially, we are attempting to model the time spent in the hospital using only health metrics measured at the hospital.

Consider the model

\[
Y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_1 x_2 + \beta_5 x_1 x_3 + \beta_6 x_2 x_3 + \beta_7 x_1 x_2 x_3 + \epsilon,
\]

where

- $Y$ is `Days`
- $x_1$ is `Blood`
- $x_2$ is `Pressure`
- $x_3$ is `Rate`.

**(a)** Fit the model above. Also fit a smaller model using the provided `R` code.

```{r, eval = TRUE}
days_add = lm(Days ~ Pressure + Blood + Rate, data = hospital)
days_int = lm(Days ~ Blood*Pressure*Rate, data = hospital)

test = anova(days_add, days_int)
fteststat = test$F[2]
q3_pval = pf(fteststat, 4, 572, lower.tail=FALSE)
```

Use a statistical test to compare the two models. Report the following:

- The null and alternative hypotheses in terms of the model given in the exercise description
- The value of the test statistic
- The p-value of the test
- A statistical decision using a significance level of $\alpha = 0.10$
- Which model you prefer

</br>

Null Hypothesis: The coefficients on the interactions between Blood and Pressure, Blood and Rate, Pressure and Rate, and Blood, Pressure, and Rate are equal to zero.
</br>
Alternative Hypothesis: At least one of the coefficients on the interactions between Blood and Pressure, Blood and Rate, Pressure and Rate, and Blood, Pressure, and Rate is not equal to zero.
</br>
</br>
F Test Statistic: `r fteststat`
</br>
</br>
P-Value: `r q3_pval`
</br>
</br>
Statistical Decision: At a significance level of $\alpha = .10$, I can reject the null hypothesis that the coefficients on the interaction terms are all equal to zero. I can conclude that at least one of the coefficients on the interaction terms is not equal to zero. 
</br>
</br>
Preffered Model: I prefer the interaction model since `r q3_pval` < .10, which is our $\alpha$ level.
</br>
</br>

**(b)** Give an expression based on the model in the exercise description for the true change in length of hospital stay in days for a 1 bpm increase in `Rate` for a patient with a `Pressure` of 139 mmHg and a `Blood` of 10 gm/dL. Your answer should be a linear function of the $\beta$s.
</br>
</br>
An expression for the true change in length of hospital stay in days using the interaction model for a 1 bpm incease in Rate with a pressure of 139 mmHG and a Blood of 10 gm/dL would be:
</br>
</br>
$Days = \beta_{Rate} + 139*\beta_{Pressure*Rate} + 10*\beta_{Blood*Rate} + 139*10\beta_{Blood*Pressure*Rate}$


**(c)** Give an expression based on the additive model in part **(a)** for the true change in length of hospital stay in days for a 1 bpm increase in `Rate` for a patient with a `Pressure` of 139 mmHg and a `Blood` of 10 gm/dL. Your answer should be a linear function of the $\beta$s.
</br>
</br>
An expression for the true change in length of hospital stay in days using the additive model for a 1 bpm incease in Rate with a pressure of 139 mmHG and a Blood of 10 gm/dL would be:
</br>
</br>
$Days = \beta_{Rate}$
</br>
</br>


***

## Exercise 4 ($t$-test Is a Linear Model)

In this exercise, we will try to convince ourselves that a two-sample $t$-test assuming equal variance is the same as a $t$-test for the coefficient in front of a single two-level factor variable (dummy variable) in a linear model.

First, we set up the data frame that we will use throughout.

```{r}
n = 30

sim_data = data.frame(
  groups = c(rep("A", n / 2), rep("B", n / 2)),
  values = rep(0, n))
str(sim_data)
```

We will use a total sample size of `30`, `15` for each group. The `groups` variable splits the data into two groups, `A` and `B`, which will be the grouping variable for the $t$-test and a factor variable in a regression. The `values` variable will store simulated data.

We will repeat the following process a number of times.

```{r}
set.seed(420)
sim_data$values = rnorm(n, mean = 42, sd = 3.5) # simulate response data
summary(lm(values ~ groups, data = sim_data))
t.test(values ~ groups, data = sim_data, var.equal = TRUE)
```

We use `lm()` to test

\[
H_0: \beta_1 = 0
\]

for the model

\[
Y = \beta_0 + \beta_1 x_1 + \epsilon
\]

where $Y$ is the values of interest, and $x_1$ is a dummy variable that splits the data in two. We will let `R` take care of the dummy variable.

We use `t.test()` to test

\[
H_0: \mu_A = \mu_B
\]

where $\mu_A$ is the mean for the `A` group, and $\mu_B$ is the mean for the `B` group.

The following code sets up some variables for storage.

```{r}
num_sims = 300
lm_t = rep(0, num_sims)
lm_p = rep(0, num_sims)
tt_t = rep(0, num_sims)
tt_p = rep(0, num_sims)
```

- `lm_t` will store the test statistic for the test $H_0: \beta_1 = 0$.
- `lm_p` will store the p-value for the test $H_0: \beta_1 = 0$.
- `tt_t` will store the test statistic for the test $H_0: \mu_A = \mu_B$.
- `tt_p` will store the p-value for the test $H_0: \mu_A = \mu_B$.

The variable `num_sims` controls how many times we will repeat this process, which we have chosen to be `300`.

**(a)** Set a seed equal to your birthday. Then write code that repeats the above process `300` times. Each time, store the appropriate values in `lm_t`, `lm_p`, `tt_t`, and `tt_p`. Specifically, each time you should use `sim_data$values = rnorm(n, mean = 42, sd = 3.5)` to update the data. The grouping will always stay the same.
```{r}
set.seed(19981127)
for (i in 1:300) {
  sim_data$values = rnorm(n, mean = 42, sd = 3.5)
  mod = lm(values ~ groups, data = sim_data)
  t_test = t.test(values ~ groups, data = sim_data, var.equal = TRUE)
  
  lm_t[i] = summary(mod)$coefficients[2, 3]
  lm_p[i] = summary(mod)$coefficients[2, 4]

  tt_t[i] = t_test$statistic
  tt_p[i] = t_test$p.value
}
```


**(b)** Report the value obtained by running `mean(lm_t == tt_t)`, which tells us what proportion of the test statistics is equal. The result may be extremely surprising!
```{r}
meants = mean(lm_t == tt_t)
meants
```


**(c)** Report the value obtained by running `mean(lm_p == tt_p)`, which tells us what proportion of the p-values is equal. The result may be extremely surprising!
```{r}
meanps = mean(lm_p == tt_p)
meanps
```


**(d)** If you have done everything correctly so far, your answers to the last two parts won't indicate the equivalence we want to show! What the heck is going on here? The first issue is one of using a computer to do calculations. When a computer checks for equality, it demands **equality**; nothing can be different. However, when a computer performs calculations, it can only do so with a certain level of precision. So, if we calculate two quantities we know to be analytically equal, they can differ numerically. Instead of `mean(lm_p == tt_p)` run `all.equal(lm_p, tt_p)`. This will perform a similar calculation, but with a very small error tolerance for each equality. What is the result of running this code? What does it mean?
```{r}
all.equal(lm_p, tt_p)
```
</br>
The result of running this code is that all p values from the linear model and the t test are the same within a small error tolerance. This means that while the p values may not be 100% identical, they are analytically equal as they only differ by a very small amount, which can be denoted to error.
</br>


**(e)** Your answer in **(d)** should now make much more sense. Then what is going on with the test statistics? Look at the values stored in `lm_t` and `tt_t`. What do you notice? Is there a relationship between the two? Can you explain why this is happening?

</br>
</br>
Looking at the values stored in lm_t and tt_t, I notice that every entry for a specific simulation is opposite. So if the value in lm_t for a specific simulation is positive, the value stored in tt_t for that simulation will be the same exact value, but negative. This is happening due to the difference in test statistic equations. The numerator in the equation for the test statistic in the linear model is:
</br>
</br>
$$t = \beta_1 - 0$$
</br>
</br>
The equation for the test statistic in the two sample t test is:
</br>
</br>
$$t = \mu_A - \mu_B - 0$$
</br>
</br>
So depending on if $\beta_1$ is estimated to be positive or negative for that specific simulation depends on if the mean of group B is greater or less than the mean of group A (since A is the refence level in the models simulated). If the mean of group B is greater than the mean of group A, $\beta_1$ will be positive and therefore will result in a positive test statistic. However, if the mean of group B is greater than the mean of group A and we do a 2 sample t test, we will get a negative value for the test statistic even though we will get the same value. The equations are the reason we are getting opposite yet equal values in lm_t and tt_t.
</br>
</br>
[Check out my Github!](https://github.com/joshjanda1/Stat-420)
