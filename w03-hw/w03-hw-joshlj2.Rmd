---
title: "Week 3 - Homework"
author: "STAT 420, Summer 2019, Janda - joshlj2"
date: ''
output:
  html_document: 
    toc: yes
  pdf_document: default
urlcolor: cyan
---


## Exercise 1 (Using `lm` for Inference)

For this exercise we will use the `cats` dataset from the `MASS` package. You should use `?cats` to learn about the background of this dataset.

**(a)** Fit the following simple linear regression model in `R`. Use heart weight as the response and body weight as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `cat_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.05$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
library(MASS)
cat_model  = lm(Hwt ~ Bwt, data=cats)
test_statistic = summary(cat_model)$coefficients[2,3]#test statistic is just square root of F test statistic.
df_cat = df.residual(cat_model)
p_value = 2*pt(test_statistic, df=df_cat, lower.tail=FALSE)#or
p_value_2 = summary(cat_model)$coefficients[2,4]#will be equal to calculation above
```
$H_o$: $\beta_1$ = 0
$H_1$: $\beta_1$ $\neq$ 0
</br>
Test Statistic: `r test_statistic`
</br>
P-Value: `r p_value`
</br></br>
Statistical Decision: At $\alpha = 0.05$ I can reject the null hypothesis heavily (our p-value is $\approx$ 0). Therefore, we can conclude that $\beta_1$ $\neq$ 0 and that our model overall is significant.
</br></br>
Context Decision: We can conclude at $\alpha = 0.05$ that the body weight of cats has a linear relationship with heart weight. Therefore, body weight of cats has an overall significant impact on their heart weight.


**(b)** Calculate a 90% confidence interval for $\beta_1$. Give an interpretation of the interval in the context of the problem.
```{r}
ci_90 = confint(cat_model, 'Bwt', level=.90)
```
The 90% confidence interval for $\beta_1$ is [`r ci_90`]. In the context of the problem this means that we can be 90% certain that the true slope parameter for the effect of body weight on heart weight is contained in this interval. </br>

**(c)** Calculate a 99% confidence interval for $\beta_0$. Give an interpretation of the interval in the context of the problem.
```{r}
ci_99 = confint(cat_model, '(Intercept)', level=.99)
```
The 99% confidence interval for $\beta_0$ is [`r ci_99`]. In the context of the problem this means that if the body weight of a cat equals zero, then we can be 99% certain that the true heart weight of the cat would be contained in this interval.
</br>

**(d)** Use a 99% confidence interval to estimate the mean heart weight for body weights of 2.1 and 2.8 kilograms. Which of the two intervals is wider? Why?
```{r}
predict_df = data.frame(Bwt = c(2.1, 2.8))
ci_99_mean = predict.lm(cat_model, newdata = predict_df, level = .99, interval = 'confidence')
ci_99_21 = c(ci_99_mean[1,2], ci_99_mean[1,3])
ci_99_28 = c(ci_99_mean[2,2], ci_99_mean[2,3])
mean(cats$Bwt)
```
2.1Kg 99% CI: [`r ci_99_21`]
</br>
2.8Kg 99% CI: [`r ci_99_28`]
</br>
The 2.1Kg confidence interval for the mean is wider. This is due to 2.1Kg being farther away from the actual mean of the body weight variable. Since the confidence interval for mean values contains the equation $(x^* - \bar x)^2$, point estimates that are farther from the mean will have a wider confidence interval.
</br>

**(e)** Use a 99% prediction interval to predict the heart weight for body weights of 2.8 and 4.2 kilograms.
```{r}
predict_dfe = data.frame(Bwt = c(2.8, 4.2))
ci_99_e = predict.lm(cat_model, newdata = predict_dfe, level = .99, interval = 'prediction')
ci_99e_28 = c(ci_99_e[1,2], ci_99_e[1,3])
ci_99e_42 = c(ci_99_e[2,2], ci_99_e[2,3])
```
2.8Kg 99% Prediction Interval: [`r ci_99e_28`]
</br>
4.2Kg 99% Prediction Interval: [`r ci_99e_42`]

**(f)** Create a scatterplot of the data. Add the regression line, 90% confidence bands, and 90% prediction bands.
```{r}
library(ggplot2)
predict_new = predict.lm(cat_model, interval = 'prediction', level=.90)
colnames(predict_new) = c("fit_pred", "pred_lwr", "pred_upr")

confidence_new = predict.lm(cat_model, interval = 'confidence', level = .90)
colnames(confidence_new) = c("fit_conf", "conf_lwr", "conf_upr")

graph_df = cbind(cats, predict_new, confidence_new)

ggplot(graph_df, aes(x = Bwt, y = Hwt)) + geom_point(color = 'orange') + geom_smooth(method = 'lm', formula = y ~ x, level = .90, aes(color = 'regression'), se = FALSE) + geom_line(aes(y=pred_lwr, color = 'pred_lwr'), linetype = 'dashed') + geom_line(aes(y=pred_upr, color = 'pred_upr'), linetype = 'dashed') + geom_line(aes(y=conf_lwr, color = 'conf_lwr')) + geom_line(aes(y=conf_upr, color = 'conf_upr')) + ggtitle("Heart Weight vs. Body Weight in Cats") + xlab('Body Weight') + ylab('Heart Weight') + scale_color_manual(name = 'Legend', values = c('pred_lwr' = "green", 'pred_upr' = "green", 'regression' = 'blue', 'conf_lwr' = 'darkorchid4', 'conf_upr' = 'darkorchid4'), labels = c('90% Confidence Bands', '90% Confidence Bands', '90% Prediction Bands', '90% Prediction Bands', 'Regression Line')) + theme(plot.title = element_text(hjust = 0.5))
```


**(g)** Use a $t$ test to test:

- $H_0: \beta_1 = 4$
- $H_1: \beta_1 \neq 4$

Report the following:

- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.05$

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
test_statistic_g = (cat_model$coefficients[[2]] - 4) / summary(cat_model)$coefficients[2,2]
p_value_g = 2*pt(test_statistic_g, df = df_cat, lower.tail = FALSE)

```
Test Stastic: `r test_statistic_g`</br>
P-Value: `r p_value_g`</br>
Statistical Decision: At $\alpha = 0.05$, we fail to reject the null hypothesis that $\beta_1 = 4$. That is, the probability that $\beta_1 = 4$ is greater than p = .05.

***

## Exercise 2 (More `lm` for Inference)

For this exercise we will use the `Ozone` dataset from the `mlbench` package. You should use `?Ozone` to learn about the background of this dataset. You may need to install the `mlbench` package. If you do so, do not include code to install the package in your `R` Markdown document.

For simplicity, we will re-perform the data cleaning done in the previous homework.

```{r}
data(Ozone, package = "mlbench")
Ozone = Ozone[, c(4, 6, 7, 8)]
colnames(Ozone) = c("ozone", "wind", "humidity", "temp")
Ozone = Ozone[complete.cases(Ozone), ]
```

**(a)** Fit the following simple linear regression model in `R`. Use the ozone measurement as the response and wind speed as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `ozone_wind_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
ozone_wind_model  = lm(ozone ~ wind, data = Ozone)
test_stat_2a = (ozone_wind_model$coefficients[[2]] - 0) / summary(ozone_wind_model)$coefficients[2,2]
p_value_2a = 2*pt(test_stat_2a, df = df.residual(ozone_wind_model), lower.tail = TRUE)
```
$H_o$: $\beta_1$ = 0
$H_1$: $\beta_1$ $\neq$ 0
</br>
Test Statistic: `r test_stat_2a`
</br>
P-Value: `r p_value_2a`
</br></br>
Statistical Decision: At $\alpha = 0.01$, we fail to reject our null hypothesis that $\beta_1$ = 0. Therefore, we can conclude that our overall regression model is not significant at $\alpha = 0.01$. 
</br>
Contextual Decision: Our model is overall not significant. We can conclude that there is a not a significant linear relationship between wind speed and ozone measuremeant. Wind speed does not have a significant effect on ozone measuremeant. 

**(b)** Fit the following simple linear regression model in `R`. Use the ozone measurement as the response and temperature as the predictor. 

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Store the results in a variable called `ozone_temp_model`. Use a $t$ test to test the significance of the regression. Report the following:

- The null and alternative hypotheses
- The value of the test statistic
- The p-value of the test
- A statistical decision at $\alpha = 0.01$
- A conclusion in the context of the problem

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.
```{r}
ozone_temp_model  = lm(ozone ~ temp, data = Ozone)
test_stat_2b = (ozone_temp_model$coefficients[[2]] - 0) / summary(ozone_temp_model)$coefficients[2,2]
p_value_2b = 2*pt(test_stat_2b, df = df.residual(ozone_temp_model), lower.tail = FALSE)
```
$H_o$: $\beta_1$ = 0
$H_1$: $\beta_1$ $\neq$ 0
</br>
Test Statistic: `r test_stat_2b`
</br>
P-Value: `r p_value_2b`
</br></br>
Statistical Decision: At $\alpha = 0.01$, we can reject our null hypothesis that $\beta_1$ = 0. Therefore, we can conclude that our overall regression model is significant $\alpha = 0.01$ and that there is a significant linear effect of temperature on ozone measurement.
</br>
Contextual Decision: Our model is overall significant. We can conclude that there is a significant linear relationship between temperature and ozone measurement and that temperature does have a significant effect on ozone measurement.

***

## Exercise 3 (Simulating Sampling Distributions)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = -5$
- $\beta_1 = 3.25$
- $\sigma^2 = 16$

We will use samples of size $n = 50$.

**(a)** Simulate this model $2000$ times. Each time use `lm()` to fit a simple linear regression model, then store the value of $\hat{\beta}_0$ and $\hat{\beta}_1$. Set a seed using **your** birthday before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
birthday = 19981127
set.seed(birthday)
n = 50
x = seq(0, 10, length = n)
beta_df = data.frame(beta0hat = rep(0, 2000), beta1hat = rep(0, 2000))

for (i in 1:2000) {
  eps = rnorm(50, mean=0, sd=4)
  y = -5 + 3.25*x + eps 
  temp_model = lm(y ~ x)
  beta_df$beta0hat[i] = temp_model$coefficients[[1]]
  beta_df$beta1hat[i] = temp_model$coefficients[[2]]
}
```

**(b)** Create a table that summarizes the results of the simulations. The table should have two columns, one for $\hat{\beta}_0$ and one for $\hat{\beta}_1$. The table should have four rows:

- A row for the true expected value given the known values of $x$
- A row for the mean of the simulated values
- A row for the true standard deviation given the known values of $x$
- A row for the standard deviation of the simulated values
```{r}
library(knitr)
Sxx = sum((x - mean(x))^2)
q3_bsummary = data.frame(
                          true_mean = c(beta0_hat = -5, beta1_hat = 3.25),
                          sim_mean = c(beta0 = mean(beta_df$beta0hat), beta1 = mean(beta_df$beta1hat)),
                          true_std = c(beta0 = sqrt(16*(1/50 + mean(x)^2 / Sxx)), beta1 = sqrt(16 / Sxx)),
                          sim_std = c(beta0 = sd(beta_df$beta0hat), beta1 = sd(beta_df$beta1hat))
)
kable(t(q3_bsummary))
```



**(c)** Plot two histograms side-by-side:

- A histogram of your simulated values for $\hat{\beta}_0$. Add the normal curve for the true sampling distribution of $\hat{\beta}_0$.
- A histogram of your simulated values for $\hat{\beta}_1$. Add the normal curve for the true sampling distribution of $\hat{\beta}_1$.
```{r}
library(ggplot2)
library(gridExtra)
Sxx = sum((x - mean(x))^2)
sd_b0 = sqrt(16*(1/50 + mean(x)^2 / Sxx))
sd_b1 = sqrt(16 / Sxx)

plot_beta0hat = ggplot(beta_df, aes(x = beta0hat)) + geom_histogram(aes(y = ..density..), bins=60) + stat_function(fun = dnorm, aes(color = 'beta0'), size = 2, args = list(mean = -5, sd = sd_b0)) + ggtitle("Beta 0 Hat Distribution") + xlab("Simulated Beta 0 Hat Values") + ylab("Density") + theme(plot.title = element_text(hjust=.5), legend.position = "bottom") + scale_color_manual(name="", values = c("beta0" = "red"), labels = "Beta 0 True Distribution")
plot_beta1hat = ggplot(beta_df, aes(x = beta1hat)) + geom_histogram(aes(y = ..density..), bins=60) + stat_function(fun = dnorm, aes(color = 'beta1'), size = 2, args = list(mean = 3.25, sd = sd_b1)) + ggtitle("Beta 1 Hat Distribution") + xlab("Simulated Beta 1 Hat Values") + ylab("Density") + theme(plot.title = element_text(hjust=.5), legend.position = "bottom") + scale_color_manual(name="", values = c("beta1" = "red"), labels = "Beta 1 True Distribution")
grid.arrange(plot_beta0hat, plot_beta1hat, ncol=2)
```


***

## Exercise 4 (Simulating Confidence Intervals)

For this exercise we will simulate data from the following model:

\[
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i
\]

Where $\epsilon_i \sim N(0, \sigma^2).$ Also, the parameters are known to be:

- $\beta_0 = 5$
- $\beta_1 = 2$
- $\sigma^2 = 9$

We will use samples of size $n = 25$.

Our goal here is to use simulation to verify that the confidence intervals really do have their stated confidence level. Do **not** use the `confint()` function for this entire exercise.

**(a)** Simulate this model $2500$ times. Each time use `lm()` to fit a simple linear regression model, then store the value of $\hat{\beta}_1$ and $s_e$. Set a seed using **your** birthday before performing the simulation. Note, we are simulating the $x$ values once, and then they remain fixed for the remainder of the exercise.

```{r}
birthday = 19981127
set.seed(birthday)
n = 25
x = seq(0, 2.5, length = n)
```
```{r}
beta_df4 = data.frame(beta0hat = rep(0, 2500), beta1hat = rep(0, 2500), beta1se = rep(0, 2500))
for (i in 1:2500) {
  eps = rnorm(n, mean = 0, sd = 3)
  y = 5 + 2*x + eps
  
  temp_mod = lm(y ~ x)
  
  beta_df4$beta0hat[i] = temp_mod$coefficients[[1]]
  beta_df4$beta1hat[i] = temp_mod$coefficients[[2]]
  beta_df4$beta1se[i] = summary(temp_mod)$coefficients[2, 2]
}
```

**(b)** For each of the $\hat{\beta}_1$ that you simulated, calculate a 95% confidence interval. Store the lower limits in a vector `lower_95` and the upper limits in a vector `upper_95`. Some hints:

- You will need to use `qt()` to calculate the critical value, which will be the same for each interval.
- Remember that `x` is fixed, so $S_{xx}$ will be the same for each interval.
- You could, but do not need to write a `for` loop. Remember vectorized operations.
```{r}
crit_value = qt(.025, df.residual(temp_mod), lower.tail=FALSE)
Sxx = sum((x - mean(x))^2)

lower_95 = beta_df4$beta1hat - crit_value*beta_df4$beta1se
upper_95 = beta_df4$beta1hat + crit_value*beta_df4$beta1se

```

**(c)** What proportion of these intervals contains the true value of $\beta_1$?
```{r}
q4c_b1h = beta_df4$beta1hat
true = q4c_b1h[2 >= lower_95 & 2 <= upper_95]
prop_4c = length(true) / length(q4c_b1h)

```
The proportion of intervals that contain the true value of $\beta_1$ is equal to: `r prop_4c`.
</br>

**(d)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.05$?
Based on these intervals, the proportion of the simulations that would reject this null hypothesis at $\alpha = 0.05$ is .9536 rather than .95. 
</br>

**(e)** For each of the $\hat{\beta}_1$ that you simulated, calculate a 99% confidence interval. Store the lower limits in a vector `lower_99` and the upper limits in a vector `upper_99`.
```{r}
crit_value_f = qt(.01, df.residual(temp_mod), lower.tail=FALSE)
Sxx = sum((x - mean(x))^2)

lower_99 = beta_df4$beta1hat - crit_value_f*beta_df4$beta1se
upper_99 = beta_df4$beta1hat + crit_value_f*beta_df4$beta1se
```



**(f)** What proportion of these intervals contains the true value of $\beta_1$?
```{r}
q4f_b1h = beta_df4$beta1hat
true_f = q4f_b1h[2 >= lower_99 & 2 <= upper_99]
prop_4f = length(true_f) / length(q4f_b1h)
```
The proportion of intervals that contain the true value of $\beta_1$ is equal to: `r prop_4f`.
<br>
**(g)** Based on these intervals, what proportion of the simulations would reject the test $H_0: \beta_1 = 0$ vs $H_1: \beta_1 \neq 0$ at $\alpha = 0.01$?
Based on these intervals, the proportion of the simulations that would reject this null hypothesis at $\alpha = 0.01$ is .982 rather than .99. 
***

## Exercise 5 (Prediction Intervals "without" `predict`)

Write a function named `calc_pred_int` that performs calculates prediction intervals:

$$
\hat{y}(x) \pm t_{\alpha/2, n - 2} \cdot s_e\sqrt{1 + \frac{1}{n}+\frac{(x-\bar{x})^2}{S_{xx}}}.
$$

for the linear model

$$
Y_i = \beta_0 + \beta_1 x_i + \epsilon_i.
$$

**(a)** Write this function. You may use the `predict()` function, but you may **not** supply a value for the `level` argument of `predict()`. (You can certainly use `predict()` any way you would like in order to check your work.)

The function should take three inputs:

- `model`, a model object that is the result of fitting the SLR model with `lm()`
- `newdata`, a data frame with a single observation (row)
    - This data frame will need to have a variable (column) with the same name as the data used to fit `model`.
- `level`, the level (0.90, 0.95, etc) for the interval with a default value of `0.95`

The function should return a named vector with three elements:

- `estimate`, the midpoint of the interval
- `lower`, the lower bound of the interval
- `upper`, the upper bound of the interval
```{r}
calc_pred_int = function(model, newdata, level=.95) {
  x = newdata
  x_values = model$model[, 2]
  Sxx = sum((x_values - mean(x_values))^2)
  estimate = predict.lm(model, newdata)
  #print(estimate)
  se = summary(model)$sigma
  err = se*sqrt(1 + 1/length(x_values) + ((x - mean(x_values))^2 / Sxx))
  crit = qt((1 - level)/2, df.residual(model), lower.tail=FALSE)
  #print(crit)
  lower = estimate - crit*err
  #print(lower)
  upper = estimate + crit*err
  #print(upper)
  
  c(estimate = estimate, lower = lower, upper = upper)
}
```

**(b)** After writing the function, run this code:

```{r echo=TRUE}
newcat_1 = data.frame(Bwt = 4.0)
calc_pred_int(cat_model, newcat_1)
```

**(c)** After writing the function, run this code:

```{r echo=TRUE}
newcat_2 = data.frame(Bwt = 3.3)
calc_pred_int(cat_model, newcat_2, level = 0.99)
```


